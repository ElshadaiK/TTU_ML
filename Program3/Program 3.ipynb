{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blue' size = 5>Neural Networks and Deep Learning <font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Program you will use **Deep Neural Networks** to classify digits in the **mnist** dataset. This database contains a large number of handwritten digits popularly used to train various image processing systems. The training data contains images of the hand written digits and the test data contains labes (0-9) for the digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blue' size = 5>Part 1: Training and evaluating deep Neural Networks <font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As always, we will start by downloading the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libaries for the deep NN\n",
    "# from keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load mnist data into train and test sets\n",
    "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  60000  images in the training and  10000  images in the test dataset\n"
     ]
    }
   ],
   "source": [
    "# Size of the datatset\n",
    "print('There are ', len(X_train), ' images in the training and ', len(X_test), ' images in the test dataset')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the training data\n",
    "X_train[0].shape  # The images are in a 28X28 grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To have an idea about how the training data looks, we will print out the first instance of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]  # prints out the 1st image in the training set in grid format (28X28 matrix)\n",
    "# Here 0 means black spaces/cells, 255 is white. So he closer the numbers are to 255 the brighter it gets  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out what the instance looks like as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf32b54f60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[0])  # prints out the 1st image in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the label of that instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]  # Class/label of the 1st image (the labels are 0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's build a simple Neural Network with no hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: Tensor(\"input_1_1:0\", shape=(?, 784), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d34d00c06119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# flatten the training set matrices into 1d arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0;31m# input layer (shape became 784 after flattening)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ])\n",
      "\u001b[0;32m/Users/elshadai/anaconda3/envs/ml-assignment/lib/python3.5/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elshadai/anaconda3/envs/ml-assignment/lib/python3.5/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    129\u001b[0m             raise TypeError('The added layer must be '\n\u001b[1;32m    130\u001b[0m                             \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                             'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: Tensor(\"input_1_1:0\", shape=(?, 784), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([                 # initialize the model\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),   # flatten the training set matrices into 1d arrays\n",
    "    keras.Input(shape=(784,)),                    # input layer (shape became 784 after flattening)\n",
    "    keras.layers.Dense(10, activation='sigmoid')  # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() # gives you a summary of the model that has been built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model with X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_original = model.fit(X_train, y_train, batch_size=100, epochs=20) # epochs indicate the number of times the model has gone through the whole training dataset\n",
    "                                                       # batch_size (default 32) is the number of training sample the model goes through at a time before updating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model with X_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_original = model.evaluate(X_test, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train_original = training_original.history['accuracy'][len(training_original.history['accuracy']) - 1]\n",
    "loss_train_original = training_original.history['loss'][len(training_original.history['loss']) - 1]\n",
    "accuracy_test_original = evaluation_original[1]\n",
    "loss_test_original = evaluation_original[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see that at the simplest state, with no hidden layers, the Neural Network achieves a training accuracy of around **89%** and a test accuracy of around **87%** (may vary each time). For the training set, the accuracy of the model improves with each epoch and the loss decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red' size = 4>You will do the rest of the program yourself. Follow the instructions given below to complete the assignment.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add hidden layers to your neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add 2/3 hidden layers to your neural network. Set the activation functions for those layers as ReLU.\n",
    "- #### Compile the new model (name it something other than 'model')\n",
    "- #### Fit and evaluate the new model and record the accuracy.\n",
    "- #### Compare the difference between train and test accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "new_model = keras.models.Sequential([               \n",
    "    keras.layers.Flatten(input_shape=(28, 28)),   \n",
    "    keras.Input(shape=(784,)),                    \n",
    "    keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "    keras.layers.Dense(10, activation='selu'),\n",
    "    keras.layers.Dense(20, activation='sigmoid')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training = new_model.fit(X_train, y_train, batch_size=100, epochs=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_evaluation = new_model.evaluate(X_test, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_training = new_training.history['accuracy'][len(new_training.history['accuracy']) - 1]\n",
    "loss_training = new_training.history['loss'][len(new_training.history['loss']) - 1]\n",
    "accuracy_test = new_evaluation[1]\n",
    "loss_test = new_evaluation[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In our own words, write how the accuracies for the new model differed from that of the previous one.\n",
    "- #### Why do you think the accuracy improved/worsened?\n",
    "- #### What is the importance of hidden layers in a Neural Network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green' size = 2>Write answer here<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, an artificial neural network consists of an input layer where it receives inputs and output layer where it outputs. The hidden layer is a layer which is hidden in between input and output layers since the output of one layer is the input of another layer. \n",
    "The hidden layers perform computations on the weighted inputs and produce net input which is then applied with activation functions to produce the actual output. The computations that the hidden layers perform (the way the hidden layers are setup) and the activation functions used depend on the type of neural network used which in turn depends on the application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blue' size = 5>Part 2: Avoiding Overfitting Through Regularization<font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapter 11 of the textbook demonstrates two methods of avoiding overfitting through regularization.\n",
    "- #### â„“2 Regularization, and\n",
    "- #### Dropout\n",
    "#### You will use both methods and see how the performance changes for the model.  \n",
    "#### See the Avoiding Overfitting Through Regularization section of the textbook (p. 364)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# other libraries\n",
    "from functools import partial\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for implementing and evaluating l2 regularization\n",
    "RegulaziedDense = partial(keras.layers.Dense,\n",
    "                         kernel_initializer='he_normal',\n",
    "                         kernel_regularizer=keras.regularizers.l2(0.05))\n",
    "\n",
    "l2_model = keras.models.Sequential([               \n",
    "    keras.layers.Flatten(input_shape=(28, 28)),   \n",
    "    keras.Input(shape=(784,)),                    \n",
    "    RegulaziedDense(30),\n",
    "    RegulaziedDense(20),\n",
    "    RegulaziedDense(10),\n",
    "    keras.layers.Dense(10, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "# Compiling new model\n",
    "l2_model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_l2 = new_model.fit(X_train, y_train, batch_size=100, epochs=20)\n",
    "evaluation_l2 = new_model.evaluate(X_test, y_test, batch_size=100)\n",
    "\n",
    "accuracy_training_l2 = training_l2.history['accuracy'][len(training_l2.history['accuracy']) - 1]\n",
    "loss_training_12 = training_l2.history['loss'][len(training_l2.history['loss']) - 1]\n",
    "accuracy_test_l2 = evaluation_l2[1]\n",
    "loss_test_l2 = evaluation_l2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"L2 Regularization\\n\")\n",
    "print(\"Training of the model:\\tAccuracy: \" + str(round(accuracy_training_l2 * 100, 2)) + \"%\" + \"\\tLoss: \" + str(round(loss_training_12 * 100, 2)) + \"%\\n\")\n",
    "print(\"Testing of the model:\\tAccuracy: \" + str(round(accuracy_test_l2 * 100, 2)) + \"%\\t\" + \"Loss: \" + str(round(loss_test_l2 * 100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker(dropout=0.1):\n",
    "    model = keras.models.Sequential([               \n",
    "                keras.layers.Flatten(input_shape=(28, 28)),   \n",
    "                keras.Input(shape=(784,)),                    \n",
    "                keras.layers.Dense(500, activation='relu'),\n",
    "                keras.layers.Dropout(dropout),\n",
    "                keras.layers.Dense(100, activation='relu'),\n",
    "                keras.layers.Dropout(dropout),\n",
    "                keras.layers.Dense(50, activation='relu'),\n",
    "                keras.layers.Dropout(dropout),\n",
    "                keras.layers.Dense(10, activation='sigmoid') \n",
    "        ])\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                loss='sparse_categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "                  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model_maker, dropout=0.1)\n",
    "params = {'dropout': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "gs_cv = GridSearchCV(model, params, cv=4)\n",
    "gs_cv.fit(X_train, y_train, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for implementing and evaluating dropout\n",
    "# Experiment with 2-3 different dropout rates OR\n",
    "# 10 points extra credit for successfully using gridsearch to search for a good dropout rate\n",
    "dropout_model = model_maker(gs_cv.best_params_['dropout'])\n",
    "\n",
    "training_dropout = dropout_model.fit(X_train, y_train, batch_size=100, epochs=20)\n",
    "evaluation_dropout = dropout_model.evaluate(X_test, y_test, batch_size=100)\n",
    "\n",
    "accuracy_training_dropout = training_dropout.history['accuracy'][len(training_dropout.history['accuracy']) - 1]\n",
    "loss_training_dropout = training_dropout.history['loss'][len(training_dropout.history['loss']) - 1]\n",
    "accuracy_test_dropout = evaluation_dropout[1]\n",
    "loss_test_dropout = evaluation_dropout[0]\n",
    "\n",
    "print(\"Model with Dropout Regularization\\n\")\n",
    "print(\"Training of the model: \\tAccuracy: \" + str(round(accuracy_training_dropout * 100, 2)) + \"%\" + \n",
    "      \"\\tLoss: \" + str(round(loss_training_dropout * 100, 2)) + \"%\\n\")\n",
    "print(\"Testing the model: \\tAccuracy: \" + str(round(accuracy_test_dropout * 100, 2)) + \"%\\t\" + \"Loss: \" + \n",
    "      str(round(loss_test_dropout * 100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blue' size = 5>Part 3: Convolutional Neural Networks<font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement a model on the same data that uses Convolutional Neural Network (CNN) to classify the digits. See the CNN Architectures section of the textbook (p. 461) for some guidance on this.\n",
    "- #### Compile, fit and evaluate the model.\n",
    "- #### Print a table comparinig the accuracies of each models implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for CNN here\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                       kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "cnn_model = keras.models.Sequential([\n",
    "            DefaultConv2D(filters=64, kernel_size=7, input_shape=(28, 28, 1)),\n",
    "            keras.layers.MaxPooling2D(pool_size=2),\n",
    "            DefaultConv2D(filters=128),\n",
    "            DefaultConv2D(filters=128),\n",
    "            keras.layers.MaxPooling2D(pool_size=2),\n",
    "            DefaultConv2D(filters=256),\n",
    "            DefaultConv2D(filters=256),\n",
    "            keras.layers.MaxPooling2D(pool_size=2),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(units=128, activation='relu'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(units=64, activation='relu'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(units=10, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "training_cnn = cnn_model.fit(X_train, y_train, batch_size=100, epochs=20)\n",
    "evaluation_cnn = cnn_model.evaluate(X_test, y_test, batch_size=100)\n",
    "\n",
    "\n",
    "accuracy_training_cnn = training_cnn.history['accuracy'][len(training_cnn.history['accuracy']) - 1]\n",
    "loss_training_cnn = training_cnn.history['loss'][len(training_cnn.history['loss']) - 1]\n",
    "accuracy_test_cnn = evaluation_cnn[1]\n",
    "loss_test_cnn = evaluation_cnn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CNN\\n\")\n",
    "print(\"Training of the model: \\tAccuracy: \" + str(round(accuracy_training_cnn * 100, 2)) + \"%\" + \n",
    "      \"\\tLoss: \" + str(round(loss_training_cnn * 100, 2)) + \"%\\n\")\n",
    "print(\"Testing of the model: \\tAccuracy: \" + str(round(accuracy_test_cnn * 100, 2)) + \"%\\t\" + \n",
    "      \"Loss: \" + str(round(loss_test_cnn * 100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableConstructor(results, labels, columns):\n",
    "    print(\"Model Result Comparison (in %):\\n\")\n",
    "    df1 = pd.DataFrame( results,\n",
    "                        index = pd.Index(labels),\n",
    "                        columns = columns)\n",
    "    print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Regular Model', 'Hidden Layer Model', 'L2 Reg. Model', 'Dropout Reg. Model', 'CNN']\n",
    "columns = ['Training Acc.', 'Training Loss', 'Testing Acc.', 'Testing Loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results.clear()\n",
    "results.append([round(accuracy_train_original * 100 ,2), round(loss_train_original ,2), \n",
    "                round(accuracy_test_original * 100 ,2), round(loss_test_original ,2)])\n",
    "\n",
    "results.append([round(accuracy_training * 100 ,2), round(loss_training ,2), \n",
    "                round(accuracy_test * 100 ,2), round(loss_test ,2)])\n",
    "\n",
    "results.append([round(accuracy_training_l2 * 100 ,2), round(loss_training_12 ,2), \n",
    "                round(accuracy_test_l2 * 100 ,2), round(loss_test_l2 ,2)])\n",
    "\n",
    "results.append([round(accuracy_training_dropout * 100 ,2), round(loss_training_dropout ,2), \n",
    "                round(accuracy_test_dropout * 100 ,2), round(loss_test_dropout ,2)])\n",
    "\n",
    "results.append([round(accuracy_training_cnn * 100, 2), round(loss_training_cnn ,2), \n",
    "                round(accuracy_test_cnn * 100, 2), round(loss_test_cnn ,2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TableConstructor(results, labels, columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
