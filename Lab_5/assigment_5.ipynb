{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de604b1",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094ed4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61357806",
   "metadata": {},
   "source": [
    "**<font color=\"red\" size=4>Import the classifiers (Decision tree, Random Forest and Bagging)<font>**\n",
    "- <font color=\"red\" size=4> **Note:** Make sure to import base estimator classifier for Baggingclassifier\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5136421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21fd15",
   "metadata": {},
   "source": [
    "## Create a list to hold the names of csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10288b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_names = ['BankNote_Authentication.csv', 'diabetes.csv', 'seeds.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600f4e0",
   "metadata": {},
   "source": [
    "**<font color=\"red\" size=4>Now make 3 lists to hold accuracies for each classifier</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6b6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "dtc_accuracy = []\n",
    "dtc_run_accuracy = []\n",
    "rfc_accuracy = []\n",
    "rfc_run_accuracy = []\n",
    "bc_accuracy = []\n",
    "bc_run_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92108d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support variables for \"wins\"\n",
    "RF_V_DT = 0 \n",
    "RF_V_BC = 0\n",
    "DC_V_BC = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d37d2e",
   "metadata": {},
   "source": [
    "## Create a function that :\n",
    "- **takes in a csv file name as parameter**\n",
    "- **loads tha dataset**\n",
    "- **splits data into X and y**\n",
    "- **performs train_test_split**\n",
    "- **returns the train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6ea682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **NOTE** Imports necessary for these actions (pandas and train_test_split) has been done before \n",
    "\n",
    "def processing(csv):\n",
    "    dataset= pd.read_csv(csv)  \n",
    "    X = dataset.iloc[:, :-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size = 0.25,random_state=0)\n",
    "    \n",
    "    return X_tr, X_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44b24a3",
   "metadata": {},
   "source": [
    "**<font color=\"red\" size=4>Now use the example for the funtion shown above and online resources to create your own prediction function that: </font>**\n",
    "- <font color=\"red\" size=4> Takes in a classifier and the train and test data as parameters</font>\n",
    "- <font color=\"red\" size=4> Fits the classifier with X_train and y_train</font>\n",
    "- <font color=\"red\" size=4> Predicts with X_test</font>\n",
    "- <font color=\"red\" size=4> Calculates accuracy</font>\n",
    "- <font color=\"red\" size=4> Returns accuracy rounded to 6 decimal digits</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817d3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def accuracy_calculator(classifier, x_train, x_test, y_train, y_test):\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_predicted = classifier.predict(x_test)\n",
    "    return round(accuracy_score(y_test, y_predicted), 6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca0e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize classifiers\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "bagging_classifier = BaggingClassifier(base_estimator=SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f384b078",
   "metadata": {},
   "source": [
    "**<font color=\"red\" size=4>For the rest of your lab, you will write a code that,</font>**\n",
    "- <font color=\"red\" size=4> 'for' each dataset</font>\n",
    "- <font color=\"red\" size=4> Computes accuracy for 5 runs for each classifier</font>\n",
    "\n",
    "**<font color=\"red\" size=4> and prints out the following:</font>** \n",
    "- <font color=\"red\" size=4> all 5 accuracies for each 3 classifiers</font>\n",
    "- <font color=\"red\" size=4> average accuracy for each classifier</font>\n",
    "- <font color=\"red\" size=4> how many times each classifier won out of 5 runs (RFvDT, RFvBC, BCvDT)</font>\n",
    "\n",
    "**Follow the steps in the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe84a070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset number: 1\n",
      "Accuracies for Decision tree: \n",
      "[0.979592, 0.988338, 0.979592, 0.988338, 0.988338]\n",
      "Average accuracy for Decision tree: \n",
      "0.9848396000000001\n",
      "Accuracies for Random forest: \n",
      "[0.991254, 0.991254, 0.994169, 0.991254, 0.988338]\n",
      "Average accuracy for Random forest: \n",
      "0.9912538\n",
      "Accuracies for Bagging classifier: \n",
      "[1.0, 1.0, 1.0, 0.997085, 0.997085]\n",
      "Average accuracy for Bagging classifier: \n",
      "0.9988340000000001\n",
      "Times Random Forest was better than Decision Tree: 4\n",
      "Times Random Forest was better than Bagging Classifier: 0\n",
      "Times Decision Tree was better than Bagging Classifier: 0\n",
      "\n",
      "Dataset number: 2\n",
      "Accuracies for Decision tree: \n",
      "[0.729167, 0.71875, 0.708333, 0.723958, 0.71875]\n",
      "Average accuracy for Decision tree: \n",
      "0.7197916\n",
      "Accuracies for Random forest: \n",
      "[0.802083, 0.78125, 0.791667, 0.796875, 0.770833]\n",
      "Average accuracy for Random forest: \n",
      "0.7885416000000001\n",
      "Accuracies for Bagging classifier: \n",
      "[0.765625, 0.765625, 0.760417, 0.765625, 0.78125]\n",
      "Average accuracy for Bagging classifier: \n",
      "0.7677084\n",
      "Times Random Forest was better than Decision Tree: 5\n",
      "Times Random Forest was better than Bagging Classifier: 0\n",
      "Times Decision Tree was better than Bagging Classifier: 0\n",
      "\n",
      "Dataset number: 3\n",
      "Accuracies for Decision tree: \n",
      "[0.9, 0.88, 0.9, 0.9, 0.9]\n",
      "Average accuracy for Decision tree: \n",
      "0.8960000000000001\n",
      "Accuracies for Random forest: \n",
      "[0.9, 0.9, 0.9, 0.88, 0.9]\n",
      "Average accuracy for Random forest: \n",
      "0.8960000000000001\n",
      "Accuracies for Bagging classifier: \n",
      "[0.88, 0.88, 0.88, 0.88, 0.9]\n",
      "Average accuracy for Bagging classifier: \n",
      "0.884\n",
      "Times Random Forest was better than Decision Tree: 1\n",
      "Times Random Forest was better than Bagging Classifier: 2\n",
      "Times Decision Tree was better than Bagging Classifier: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "data_number = 0\n",
    "\n",
    "# For each dataset\n",
    "for data in csv_names:\n",
    "    # get train and test data (call the processing function with the right csv name index)\n",
    "    x_train, x_test, y_train, y_test = processing(data)\n",
    "    # For i = 0-5\n",
    "    for i in range(0, 5):\n",
    "        # get accuracy for decision tree (call your function)\n",
    "        dt_acc = accuracy_calculator(decision_tree, x_train, x_test, y_train, y_test)\n",
    "        # add DT accuracy to the correct accuracy list\n",
    "        dtc_accuracy.append(dt_acc)\n",
    "        # get accuracy for random forest \n",
    "        rf_acc = accuracy_calculator(random_forest, x_train, x_test, y_train, y_test)\n",
    "        # add RF accuracy to the correct accuracy list\n",
    "        rfc_accuracy.append(rf_acc)\n",
    "        # get accuracy for bagging classifier\n",
    "        bc_acc = accuracy_calculator(bagging_classifier, x_train, x_test, y_train, y_test)\n",
    "        # add BC accuracy to the correct accuracy list\n",
    "        bc_accuracy.append(bc_acc)\n",
    "        # figure out ways to calculate average accuracy and number of wins\n",
    "        if(rf_acc > dt_acc):\n",
    "            RF_V_DT += 1\n",
    "        elif(rf_acc > bc_acc):\n",
    "            RF_V_BC += 1\n",
    "        elif(dt_acc > bc_acc):\n",
    "            DC_V_BC += 1\n",
    "        # (add whatever extra things you need for that calculation)\n",
    "            \n",
    "    # print dataset number (i)\n",
    "    print(\"Dataset number: \" + str(data_number + 1))\n",
    "    \n",
    "    # print all 5 accuracies for decision tree\n",
    "    print(\"Accuracies for Decision tree: \")\n",
    "    print(dtc_accuracy)\n",
    "    # print avg accuracy for decision tree\n",
    "    print(\"Average accuracy for Decision tree: \")\n",
    "    print(sum(dtc_accuracy) / 5)\n",
    "    dtc_accuracy.clear()\n",
    "    \n",
    "    # print all 5 accuracies for random forest\n",
    "    print(\"Accuracies for Random forest: \")\n",
    "    print(rfc_accuracy)\n",
    "    # print avg accuracy for random forest\n",
    "    print(\"Average accuracy for Random forest: \")\n",
    "    print(sum(rfc_accuracy) / 5)\n",
    "    rfc_accuracy.clear()\n",
    "    \n",
    "    # print all 5 accuracies for bagging\n",
    "    print(\"Accuracies for Bagging classifier: \")\n",
    "    print(bc_accuracy)\n",
    "    # print avg accuracy for bagging\n",
    "    print(\"Average accuracy for Bagging classifier: \")\n",
    "    print(sum(bc_accuracy) / 5)\n",
    "    bc_accuracy.clear()\n",
    "    \n",
    "    # print Random Forest vs Decision Tree: wins/5\n",
    "    print(\"Times Random Forest was better than Decision Tree: \" + str(RF_V_DT))\n",
    "    # print Random Forest vs Decision Tree: wins/5\n",
    "    print(\"Times Random Forest was better than Bagging Classifier: \" + str(RF_V_BC))\n",
    "    # print Random Forest vs Decision Tree: wins/5\n",
    "    print(\"Times Decision Tree was better than Bagging Classifier: \" + str(DC_V_BC))\n",
    "    \n",
    "    RF_V_DT = 0\n",
    "    RF_V_BC = 0\n",
    "    DV_V_BC = 0\n",
    "    \n",
    "    print()\n",
    "    data_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2750b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
